{
 "metadata": {
  "celltoolbar": "Slideshow",
  "name": "",
  "signature": "sha256:590d5d33710aef02cca186b9a7a9963be0f4b0585b206cd60362e1370442b1bd"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Functional testing with Docker\n",
      "==============================\n",
      "\n",
      "George Schneeloch\n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "About Core\n",
      "==========\n",
      "\n",
      " - Analysis of mass spec data\n",
      " - Internal PHP web application, LAMP stack, Python test framework, C++ utilities\n",
      " - Messy legacy codebase, few units to test\n",
      " - Average workflow takes a half hour to complete\n",
      "<img src=\"files/small_mass_spec.jpg\" style=\"position: absolute; left: 300px; top: 500px;\" />"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      " - Talk about Core, need for testing when I started, tabular data, disorganized file structure\n",
      " - Wanted to treat application as black box. Drove tests starting with Selenium then wrote REST api to take over"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Functional testing\n",
      "==================\n",
      "\n",
      " - Decided on functional tests as the quickest route toward basic test coverage\n",
      " - Functional tests are slow, working with a clean slate is slower\n",
      " - Testing without a clean slate adds unnecessary complication"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      " - Talk about usefulness of a clean slate: trivial id numbers in input and output, can rule out interference from other components\n",
      " - Functional testing is conceptually simpler for a messy system\n",
      " - Docker makes functional tests fast due to quick setup and teardown"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Docker\n",
      "======\n",
      "\n",
      " - Offers easy and lightweight isolation of processes (incl. files, network, users)\n",
      " - Quick automatic snapshots of entire file system"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      " - Talk a bit about Docker's internals:\n",
      "   - File system records differences in state, making for lightweight snapshots\n",
      "   - Sets up networking with own ip address, routing tables\n",
      "   - Start with base Ubuntu image, install Debian packages, run installer script\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Core's tests\n",
      "============\n",
      "\n",
      " - Tests use Docker to manage state\n",
      " - Startup and teardown for each test is quick\n",
      " - Docker images are useful for debugging\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      " - Tests start on each commit, triggered by Jenkins\n",
      " - Currently have three test cases run in parallel on different VMs\n",
      " - Talk about using Docker to investigate test failures:\n",
      "   - Start docker image with same name as test to see file system right after failure\n",
      "   - Can also see right before failure\n",
      "   - Disposable, can edit code at will and try out ideas\n",
      "   - Python script to start and stop Apache, MySQL, job daemon\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "\n",
      "Dependencies\n",
      "============\n",
      "\n",
      " - Tests depend on other tests' images\n",
      " - Nose plugin was created to enforce test dependencies\n",
      " - `@requires` decorator specifies dependencies\n",
      " \n",
      "<img src=\"files/graph.png\" style='position: absolute; left: 0px; top: 600px;' />"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      " - Upside of dependency: allows reuse of commonly used code, easy to express a workflow and break it into testable pieces, easy to bolt on new tests\n",
      " - Downside: increased interdependency, all tests must pass\n",
      " - Nose plugin: basically rewrote test randomizer for this purpose. flag --with_dependency to trigger sorting, must subclass unittest.TestCase, rather hacky\n",
      " - @requires decorator provides information to Nose to use when sorting, otherwise doesn't do anything special\n",
      " - setup() starts image as Docker container, pings for stuff to wake up. teardown() saves container as new image"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Summary\n",
      "=======\n",
      "\n",
      " - Jenkins installs software onto clean Docker image after every commit\n",
      " - Tests form a dependency graph, are executed in order satisfying requirements\n",
      " - Each test runs in a Docker container\n",
      " - Results are saved in a Docker image named after the test\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      " - Starts image of mzloader_and_sequest\n",
      " - POSTs workflow to API, triggers ProteinSieveAlpha job\n",
      " - GET from job, wait until all executing jobs are marked as finished\n",
      " - Get stats data, compare with expected JSON file named after the test"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "test_core.py\n",
      "============"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import unittest\n",
      "from dependency_tests.plugin import requires\n",
      "\n",
      "class Core(unittest.TestCase, Framework):\n",
      "    # ...\n",
      "\n",
      "    @requires(\"test_mzloader_and_sequest\")\n",
      "    def test_protein_assembler(self):\n",
      "        self.post_to_api('bulk_queue',\n",
      "                         {'items' : [\n",
      "                             {'item': 'ExistingSavedSet',\n",
      "                              'parameters' : {\n",
      "                                  'set_ids' : [2]\n",
      "                              }},\n",
      "                             {'item' : 'ProteinAssembler',\n",
      "                              'parameters' : {\n",
      "                                  'map_name' : '',\n",
      "                                  'map_notes' : '',\n",
      "                                  'collapse_type' : 'greedy',\n",
      "                                  'match_type' : 'string',\n",
      "                                  'do_collapse' : 1,\n",
      "                                  'enzyme' : 1}}\n",
      "                         ]})\n",
      "        self.wait_for_success() # ping API every 10 seconds to see if everything finished yet\n",
      "\n",
      "        actual = self.get_from_api(\"protein_assembler/1\")\n",
      "        expected = self.read_expected(\"tsv\") # file in expected/ directory named after test\n",
      "\n",
      "        self.assertTsvEqual(expected, actual)\n",
      "\n"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "-"
      }
     },
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      " - Starts image of mzloader_and_sequest\n",
      " - POSTs workflow to API, triggers ProteinSieveAlpha job\n",
      " - GET from job, wait until all executing jobs are marked as finished\n",
      " - Get stats data, compare with expected JSON file named after the test"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "run_core.py, inside Docker container\n",
      "===================================="
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class State:\n",
      "    def __init__(self):\n",
      "        self.job_daemon = None\n",
      "        self.mysql = None\n",
      "\n",
      "    def run(self):\n",
      "        subprocess.Popen([\"/usr/sbin/apachectl\", \"start\"])\n",
      "        self.mysql = subprocess.Popen([\"/usr/bin/mysqld_safe\"])\n",
      "        print \"Waiting for mysql to start...\"\n",
      "        wait_for(lambda: subprocess.call(\n",
      "            [\"mysqladmin\", \"-u\", \"root\", \"-proot\", \"ping\"],\n",
      "            stdout=null_file, stderr=null_file) == 0)\n",
      "\n",
      "        print \"Waiting for apache to start...\"\n",
      "        wait_for(lambda: no_exception(\n",
      "            lambda: urllib2.urlopen(\"http://127.0.0.1/\").read()))\n",
      "        \n",
      "        self.job_daemon = subprocess.Popen(\n",
      "            [\"/bin/su\", \"gfyadministrator\", \"-c\", \"/usr/bin/php job_daemon.php\"],\n",
      "            cwd=\"/usr/share/gfy/cli\")\n",
      "        print \"Started core. Kill process when done!\"\n",
      "        signal.signal(signal.SIGTERM, self.handle_sigterm)\n",
      "        signal.signal(signal.SIGINT, self.handle_sigterm)\n",
      "        signal.pause()\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    State().run()\n"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "-"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      " - no_exception silences exception and returns bool, wait_for retries function if returned falsey value\n",
      " - Starts Apache, MySQL, job daemon and then listens for signals"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# run_core.py continued...\n",
      "\n",
      "    def handle_sigterm(self, signum, frame):\n",
      "        signal.signal(signal.SIGTERM, signal.SIG_DFL)\n",
      "        signal.signal(signal.SIGINT, signal.SIG_DFL)\n",
      "        print \"Received SIGTERM, %s, %s\" % (signum, frame)\n",
      "        print \"Terminating job daemon...\"\n",
      "        if self.job_daemon:\n",
      "            self.job_daemon.terminate()\n",
      "        print \"Terminating apache...\"\n",
      "        subprocess.check_call([\"/usr/sbin/apache2ctl\", \"stop\"])\n",
      "        print \"Terminating mysql...\"\n",
      "        if self.mysql:\n",
      "            subprocess.check_call([\"mysqladmin\", \"-proot\", \"shutdown\"])\n",
      "\n",
      "        if self.job_daemon:\n",
      "            print \"Waiting on job daemon...\"\n",
      "            self.job_daemon.wait()\n",
      "        print \"Waiting on apache...\"\n",
      "        wait_for(lambda: not no_exception(\n",
      "            lambda: urllib2.urlopen(\"http://127.0.0.1/\").read()))\n",
      "\n",
      "        print \"Waiting on mysql...\"\n",
      "        wait_for(lambda: subprocess.call(\n",
      "            [\"mysqladmin\", \"-u\", \"root\", \"-proot\", \"ping\"],\n",
      "            stdout=null_file, stderr=null_file) != 0)\n",
      "        \n",
      "        exit(0)\n",
      "\n"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "framework.py\n",
      "============"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def copy_from_docker(client, container_id, src, dest):\n",
      "    \"\"\"Workaround for Docker API for cp. It provides a tarball byte string\"\"\"\n",
      "    reply = client.copy(container_id, src)\n",
      "    filelike = io.BytesIO(reply.read())\n",
      "    tar = tarfile.open(fileobj = filelike)\n",
      "    file = tar.extractfile(os.path.basename(src))\n",
      "    with open(dest, 'wb') as f:\n",
      "        f.write(file.read())\n",
      "\n",
      "def run_docker_image(client, image_name, hostname):\n",
      "    print(\"Starting image %s\" % image_name)\n",
      "\n",
      "    container_id = client.create_container(image_name, \n",
      "        [\"/usr/bin/python\", \"/tmp/vagrant/run_core.py\"],\n",
      "        ports=[80], hostname=hostname)[\"Id\"]\n",
      "    if not container_id:\n",
      "        raise Exception(\"docker run command failed for image %s\" % image_name)\n",
      "\n",
      "    client.start(container_id)\n",
      "\n",
      "    return container_id"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "-"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      " - Helper function to extract files from Docker \n",
      " - Helper function to create docker container with the given image name\n",
      " - run_core.py is process #1, handles signals"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "framework.py\n",
      "============"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class Framework(object):\n",
      "    #...\n",
      "    def read_expected(self, kind, name=None):\n",
      "        if not name:\n",
      "            name = self.get_expected_name()\n",
      "\n",
      "        if kind == \"json\":\n",
      "            if not name.endswith(\".json\"):\n",
      "                name += \".json\"\n",
      "\n",
      "            path = os.path.join(\"expected\", name)\n",
      "            if not os.path.isfile(path):\n",
      "                return None\n",
      "            with open(path) as f:\n",
      "                obj = json.load(f)\n",
      "                return obj\n",
      "        elif kind == \"tsv\":\n",
      "            if not name.endswith(\".tsv\"):\n",
      "                name += \".tsv\"\n",
      "\n",
      "            path = os.path.join(\"expected\", name)\n",
      "            if not os.path.isfile(path):\n",
      "                return None\n",
      "            with open(path) as f:\n",
      "                # includes header\n",
      "                return list(row for row in csv.reader(f, delimiter='\\t') if len(row) > 0)\n",
      "\n",
      "        else:\n",
      "            raise Exception(\"Unknown parameter for read_expected: %s\" % kind)\n"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "-"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "- Methods to read expected test data using test name by default"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "framework.py\n",
      "============"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class Framework(object):\n",
      "    #...\n",
      "    def setUp(self):\n",
      "        # make sure this exists\n",
      "        self.db_conn = None\n",
      "\n",
      "        self.test_base_image = \"test_deb\"\n",
      "        self.test_prefix = \"%s_%s\" % (self.test_base_image, self.__class__.__name__)\n",
      "\n",
      "        self.hostname = \"localhost\"\n",
      "        self.db_name = \"gfy\"\n",
      "        self.docker_ip = None\n",
      "        self.container_id = None\n",
      "\n",
      "        self.docker = docker.client.Client()\n",
      "\n",
      "        # looks up function object._dependency_list, creates image name like\n",
      "        # gygilab/test_deb_CLASS_TEST\n",
      "        # where '_TEST' is blank if dependency is base image\n",
      "        image = self._get_image()\n",
      "        self.container_id = run_docker_image(self.docker, image, self.hostname)\n",
      "\n",
      "        container_info = self.docker.inspect_container(self.container_id)\n",
      "        self.docker_ip = container_info[\"NetworkSettings\"][\"IPAddress\"]\n",
      "        \n",
      "        # ... and also some code to ping database and web server to wait for them to wake\n",
      "        \n"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "-"
      }
     },
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      " - create Docker client (link to Docker's API)\n",
      " - create Docker container based on previous test name (or base image if no previous test)\n",
      " - ping database and webserver until they wake up"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "framework.py\n",
      "============"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class Framework(object):\n",
      "    def tearDown(self):\n",
      "        # WARNING: this doesn't work in Python 3 which is what we're using\n",
      "        # Not sure how to get nose to tell me if an error occurred\n",
      "        error = sys.exc_info()[0]\n",
      "        if error:\n",
      "            traceback.print_exc()\n",
      "\n",
      "        client = self.docker\n",
      "\n",
      "        try:\n",
      "            # print out job logs\n",
      "            jobs = [job for job in self.get_from_api('job_log')]\n",
      "            jobs = sorted(jobs, key = lambda x: int(x['id']))\n",
      "            for job in jobs:\n",
      "                job_id = job['id']\n",
      "                for type, size in job['filesizes'].items():\n",
      "                    if size:\n",
      "                        with open(\"./build/%s_%s.%s.log\" % (self.test_prefix,\n",
      "                                                            self._testMethodName,\n",
      "                                                            type), 'w') as f:\n",
      "                            f.write(self.get_from_api(\"job_log/%d?type=%s\" % (job_id, type)))\n",
      "\n",
      "        except Exception as e:\n",
      "            print(\"Error reading job logs: %s\" % e)\n",
      "        \n"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "-"
      }
     },
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "- Write out console logs for jobs to be collected as artifacts. Mention that Docker also logs console activity"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "framework.py\n",
      "============"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "        # tearDown contd...\n",
      "\n",
      "        # save code coverage results\n",
      "        try:\n",
      "            copy_from_docker(client, self.container_id, '/tmp/coverage/clover.xml',\n",
      "                             './build/clover-%s.xml' % self._testMethodName)\n",
      "        except Exception as e:\n",
      "            print(\"Error copying code coverage results to archive: %s\" % e)\n",
      "\n",
      "        name = \"gygilab/%s_%s\" % (self.test_prefix, self._testMethodName)\n",
      "\n",
      "        try:\n",
      "            if self.db_conn:\n",
      "                self.db_conn.close()\n",
      "                self.db_conn = None\n",
      "        except Exception as e:\n",
      "            print(\"Error stopping database: %s\" % e)\n",
      "\n",
      "        try:\n",
      "            print(\"Stopping container...\")\n",
      "            self.docker.stop(self.container_id)\n",
      "            client.commit(self.container_id, name)\n",
      "        except Exception as e:\n",
      "            print(\"Error stopping docker containers: %s\" % e)\n",
      "\n",
      "            "
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "-"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      " - copy code coverage to build artifacts\n",
      " - stop container, commit container to image, save image for next test"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Questions?\n",
      "=========\n",
      "\n",
      "George Schneeloch\n",
      "\n",
      "Gygi Lab at Harvard Medical School\n",
      "\n",
      "http://github.com/noisecapella/dependency_tests"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}